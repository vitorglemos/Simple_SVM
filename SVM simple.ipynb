{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa\n",
       "5            5.4           3.9            1.7           0.4  Iris-setosa\n",
       "6            4.6           3.4            1.4           0.3  Iris-setosa\n",
       "7            5.0           3.4            1.5           0.2  Iris-setosa\n",
       "8            4.4           2.9            1.4           0.2  Iris-setosa\n",
       "9            4.9           3.1            1.5           0.1  Iris-setosa"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Iris.csv')\n",
    "df = df.drop(['Id'],axis=1)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['Species']\n",
    "s = set()\n",
    "for val in target:\n",
    "    s.add(val)\n",
    "s = list(s)\n",
    "rows = list(range(100,150))\n",
    "df = df.drop(df.index[rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Drop rest of the features and extract the target values\n",
    "df = df.drop(['SepalWidthCm','PetalWidthCm'],axis=1)\n",
    "Y = []\n",
    "target = df['Species']\n",
    "for val in target:\n",
    "    if(val == 'Iris-setosa'):\n",
    "        Y.append(-1)\n",
    "    else:\n",
    "        Y.append(1)\n",
    "        \n",
    "df = df.drop(['Species'],axis=1)\n",
    "X = df.values.tolist()\n",
    "\n",
    "X, Y = shuffle(X,Y)\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.9)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_train = y_train.reshape(90,1)\n",
    "y_test = y_test.reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SVM():\n",
    "    def __init__(self, max_epoch, alpha):\n",
    "        self.max_epoch = max_epoch\n",
    "        self.alpha = alpha\n",
    "        self.W1 = np.zeros((90,1))\n",
    "        self.W2 = np.zeros((90,1))\n",
    "    \n",
    "    def update_w(self, w1, w2, epochs):\n",
    "        return w1 - self.alpha * (2 * 1/epochs * w1), w2 - self.alpha * (2 * 1/epochs * w2)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X1, self.X2 = X[:,0], X[:,1]\n",
    "        self.X1, self.X2 = self.X1.reshape(90,1), self.X2.reshape(90,1)\n",
    "        \n",
    "        epochs = 1\n",
    "        while(epochs < self.max_epoch):\n",
    "            output = self.W1 * self.X1 + self.W2 + self.X2\n",
    "            output_vs = output * y\n",
    "            count = 0\n",
    "            \n",
    "            for output_v in output_vs:\n",
    "                if output_v >= 1:\n",
    "                    cost = 0\n",
    "                    self.W1, self.W2 = self.update_w(self.W1, self.W2, epochs)\n",
    "                else:\n",
    "                    cost = 1 - output_v\n",
    "                    self.W1 = self.W1 + self.alpha * (self.X1[count] * y[count] - 2 * 1/epochs * self.W1)\n",
    "                    self.W2 = self.W2 + self.alpha * (self.X2[count] * y[count] - 2 * 1/epochs * self.W2)\n",
    "                    \n",
    "                count += 1\n",
    "            \n",
    "            print(f\"{epochs}, {cost}\")\n",
    "            epochs += 1\n",
    "            \n",
    "    def predict_score_test(self, X_t, y_t):\n",
    "        w1 = np.delete(self.W1, list(range(10,90)))\n",
    "        w2 = np.delete(self.W2, list(range(10,90)))\n",
    "\n",
    "        w1 = w1.reshape(10,1)\n",
    "        w2 = w2.reshape(10,1)\n",
    "\n",
    "        xt1, xt2 = X_t[:,0], X_t[:,1]\n",
    "        xt1, xt2 = xt1.reshape(10,1), xt2.reshape(10,1)\n",
    "\n",
    "        y_pred = w1 * xt1 + w2 * xt2\n",
    "        predictions = list()\n",
    "        \n",
    "        for val in y_pred:\n",
    "            if(val > 1):\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(-1)\n",
    "\n",
    "        print(f\"Score: {accuracy_score(y_test,predictions)}\")\n",
    "        \n",
    "    def get_w(self):\n",
    "        return self.W1, self.W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, [2.9]\n",
      "2, [2.785345]\n",
      "3, [2.6712352]\n",
      "4, [2.55730528]\n",
      "5, [2.44346476]\n",
      "6, [2.32967765]\n",
      "7, [2.21592601]\n",
      "8, [2.10219964]\n",
      "9, [1.98849217]\n",
      "10, [1.87479937]\n",
      "11, [1.76111829]\n",
      "12, [1.64744677]\n",
      "13, [1.53378321]\n",
      "14, [1.42012638]\n",
      "15, [1.3064753]\n",
      "16, [1.19282921]\n",
      "17, [1.07918747]\n",
      "18, [0.96554956]\n",
      "19, [0.85191507]\n",
      "20, [0.74426061]\n",
      "21, [0.63953603]\n",
      "22, [0.5437865]\n",
      "23, [0.45090385]\n",
      "24, [0.3838442]\n",
      "25, [0.33844295]\n",
      "26, [0.31312771]\n",
      "27, [0.29456254]\n",
      "28, [0.28907387]\n",
      "29, [0.28671077]\n",
      "30, [0.2842913]\n",
      "31, [0.28181924]\n",
      "32, [0.27929802]\n",
      "33, [0.28058569]\n",
      "34, [0.28182808]\n",
      "35, [0.27917279]\n",
      "36, [0.28033441]\n",
      "37, [0.28145808]\n",
      "38, [0.28254588]\n",
      "39, [0.2835997]\n",
      "40, [0.28462129]\n",
      "41, [0.2856123]\n",
      "42, [0.28271882]\n",
      "43, [0.2836547]\n",
      "44, [0.28456415]\n",
      "45, [0.28544838]\n",
      "46, [0.28630853]\n",
      "47, [0.28714564]\n",
      "48, [0.28796072]\n",
      "49, [0.28875467]\n",
      "50, [0.28952838]\n",
      "51, [0.29028266]\n",
      "52, [0.28716257]\n",
      "53, [0.28788159]\n",
      "54, [0.28858333]\n",
      "55, [0.28926843]\n",
      "56, [0.28993751]\n",
      "57, [0.29059115]\n",
      "58, [0.29122988]\n",
      "59, [0.29185424]\n",
      "60, [0.2924647]\n",
      "61, [0.29306175]\n",
      "62, [0.29364581]\n",
      "63, [0.29421732]\n",
      "64, [0.29477667]\n",
      "65, [0.29532426]\n",
      "66, [0.29586044]\n",
      "67, [0.29638556]\n",
      "68, [0.29689996]\n",
      "69, [0.29740395]\n",
      "70, [0.29789785]\n",
      "71, [0.29838193]\n",
      "72, [0.29885648]\n",
      "73, [0.29932177]\n",
      "74, [0.29977805]\n",
      "75, [0.28985402]\n",
      "76, [0.2902955]\n",
      "77, [0.29072865]\n",
      "78, [0.29115368]\n",
      "79, [0.2915708]\n",
      "80, [0.29198023]\n",
      "81, [0.29238214]\n",
      "82, [0.29277673]\n",
      "83, [0.29316418]\n",
      "84, [0.29354466]\n",
      "85, [0.29391834]\n",
      "86, [0.29428538]\n",
      "87, [0.29464594]\n",
      "88, [0.29500016]\n",
      "89, [0.2953482]\n",
      "90, [0.29326521]\n",
      "91, [0.29360177]\n",
      "92, [0.29393254]\n",
      "93, [0.29425766]\n",
      "94, [0.29215226]\n",
      "95, [0.29246688]\n",
      "96, [0.2927762]\n",
      "97, [0.29308032]\n",
      "98, [0.29095437]\n",
      "99, [0.29124887]\n",
      "100, [0.29153848]\n",
      "101, [0.2918233]\n",
      "102, [0.29210342]\n",
      "103, [0.28995397]\n",
      "104, [0.29022542]\n",
      "105, [0.29049243]\n",
      "106, [0.29075511]\n",
      "107, [0.28858855]\n",
      "108, [0.2888432]\n",
      "109, [0.28909374]\n",
      "110, [0.28934026]\n",
      "111, [0.28958282]\n",
      "112, [0.28739652]\n",
      "113, [0.28763178]\n",
      "114, [0.28786329]\n",
      "115, [0.28809112]\n",
      "116, [0.28831534]\n",
      "117, [0.28611101]\n",
      "118, [0.28632855]\n",
      "119, [0.28654266]\n",
      "120, [0.28675339]\n",
      "121, [0.2869608]\n",
      "122, [0.28473995]\n",
      "123, [0.2887468]\n",
      "124, [0.28651939]\n",
      "125, [0.28428922]\n",
      "126, [0.2882869]\n",
      "127, [0.28605047]\n",
      "128, [0.287617]\n",
      "129, [0.28918042]\n",
      "130, [0.2869352]\n",
      "131, [0.28849308]\n",
      "132, [0.29004799]\n",
      "133, [0.28779439]\n",
      "134, [0.28934401]\n",
      "135, [0.2908908]\n",
      "136, [0.29243478]\n",
      "137, [0.29017041]\n",
      "138, [0.29170943]\n",
      "139, [0.29324577]\n",
      "140, [0.29477946]\n",
      "141, [0.28455817]\n",
      "142, [0.2897819]\n",
      "143, [0.29500263]\n",
      "144, [0.28857991]\n",
      "145, [0.29379621]\n",
      "146, [0.28736913]\n",
      "147, [0.29258112]\n",
      "148, [0.2977903]\n",
      "149, [0.29135618]\n",
      "150, [0.29656123]\n",
      "151, [0.29012305]\n",
      "152, [0.29532409]\n",
      "153, [0.28888196]\n",
      "154, [0.29407909]\n",
      "155, [0.29132683]\n",
      "156, [0.29651972]\n",
      "157, [0.29376329]\n",
      "158, [0.29100526]\n",
      "159, [0.29619246]\n",
      "160, [0.29343041]\n",
      "161, [0.29066684]\n",
      "162, [0.29584856]\n",
      "163, [0.2930811]\n",
      "164, [0.29031218]\n",
      "165, [0.29548863]\n",
      "166, [0.29271596]\n",
      "167, [0.2899419]\n",
      "168, [0.29511325]\n",
      "169, [0.29233557]\n",
      "170, [0.28955654]\n",
      "171, [0.29472299]\n",
      "172, [0.29194046]\n",
      "173, [0.28915664]\n",
      "174, [0.29431836]\n",
      "175, [0.29153116]\n",
      "176, [0.28874272]\n",
      "177, [0.29389986]\n",
      "178, [0.29110815]\n",
      "179, [0.28831524]\n",
      "180, [0.29346796]\n",
      "181, [0.29067189]\n",
      "182, [0.28787467]\n",
      "183, [0.29302312]\n",
      "184, [0.29022283]\n",
      "185, [0.28742143]\n",
      "186, [0.29256575]\n",
      "187, [0.28976139]\n",
      "188, [0.28695594]\n",
      "189, [0.29545402]\n",
      "190, [0.29264539]\n",
      "191, [0.28983571]\n",
      "192, [0.28702502]\n",
      "193, [0.2955179]\n",
      "194, [0.29270413]\n",
      "195, [0.28988938]\n",
      "196, [0.28707364]\n",
      "197, [0.29556154]\n",
      "198, [0.29274285]\n",
      "199, [0.28992322]\n",
      "Score: 0.7\n"
     ]
    }
   ],
   "source": [
    "svm = SVM(200, 0.0001)\n",
    "svm.fit(x_train, y_train)\n",
    "svm.predict_score_test(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitor/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
